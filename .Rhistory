ntaxa(neg) # 2 taxa
view(tax_table(neg)) # Ruminococcus_1 and Roseburia
## inspect library sizes
sampdf <- data.frame(sample_data(psf))
sampdf$LibrarySize <- sample_sums(otu_table(psf))
sampdf <- sampdf[order(sampdf$LibrarySize), ]
sampdf$Index <- seq(nrow(sampdf))
ggplot(data = sampdf, aes(x = Index, y = LibrarySize, color = SampleBinary)) +
geom_point()
# the prevalence method of decontam is used
# we cannot use frequency due to lack of DNA quantification from experiment
sample_data(psf)$is.neg <- sample_data(psf)$SampleBinary == "Control"
contamdf.prev <- isContaminant(psf, method="prevalence", neg="is.neg", threshold=0.5)
# ---- Decontam ----
#based on negative controls
library(decontam)
library (microViz)
contamdf.prev <- isContaminant(psf, method="prevalence", neg="is.neg", threshold=0.5)
table(contamdf.prev$contaminant) # 790 taxa, no contaminants
#filter out negative control in metadata (sample_dat)
psdecon <- psf %>%
ps_filter(!str_detect(sample_names(psf), "Buff"))
ntaxa(psdecon) # 788
#save
saveRDS(psdecon, file = file.path("R/ps_decontam.Rds"))
#transform to relative abundance
pst <- psdecon %>%
tax_transform("compositional")
ntaxa(pst) #788 taxa
#save
saveRDS(pst, file = file.path("R/ps_decontam_rel.Rds"))
# load ps from relative abundance without controls
ps_rel <- readRDS("R/ps_decontam_rel.rds")
ntaxa(ps_rel) #788
# SET PATHS
RDATA = "R"
# load ps from relative abundance without controls
ps_rel <- readRDS("R/ps_decontam_rel.rds")
ntaxa(ps_rel) #788
# make df with SampleID as rownames
sampdf <- sample_data(ps_rel) %>%
data.frame() %>%
rownames_to_column(var = "SampleID")
# get diversity
alpha_shan <- estimate_richness(ps_rel, measures = "Shannon") %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
alpha_simp <- estimate_richness(ps_rel, measures = "Simpson") %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
# get summary statistics
sum <- alpha_shan %>%
group_by(Intervention, Background) %>% get_summary_stats(Shannon, type = "mean_sd")
write.table(sum, file = "out/shannon-sum-stats.txt", sep = "\t", row.names = FALSE)
# exploratory smoothed histogram
ggdensity(alpha_shan, x = "Shannon", fill = "Intervention")
ggdensity(alpha_shan, x = "Shannon", fill = "Background")
# exploratory plots
hist(alpha_shan$Shannon) #defintely skewed
ggboxplot(alpha_shan, x = "Intervention", y = "Shannon", facet.by = "Background")
# check on outliers for shannon
# table for determining outlier range
st <- alpha_shan %>% get_summary_stats(Shannon, type = "mean_sd") %>%
mutate(sdx3 = sd * 3,
outhi = mean + sdx3,
outlo = mean - sdx3)
# SD of Shannon is 0.714; Range is 1.555 to 5.839
outliershannon <- alpha_shan$SampleID[alpha_shan$Shannon < st$outlo] # none
alpha_shan$SampleID[alpha_shan$Shannon > st$outhi] # no upper outliers
# build test model for linear assumption of Intervention
# Convert Intervention to factor
alpha_shan$Intervention <- factor(alpha_shan$Intervention)
# Convert Background to factor
alpha_shan$Background <- factor(alpha_shan$Background)
# set reference level
alpha_shan$Intervention <- relevel(alpha_shan$Intervention, ref = "control")
# run linear model
testint <- lm(Shannon ~ Intervention, data = alpha_shan)
#%>%
# filter(isoutlier == F)) # more normal if outliers removed
summary(testint) #p value = 0.5577 Adj R2 = -0.02888
hist(resid(testint))
qqnorm(resid(testint))
qqline(resid(testint))
# build test model for linear assumption of Background
# set reference level
alpha_shan$Background <- relevel(alpha_shan$Background, ref = "normal total bile acid level")
testback <- lm(Shannon ~ Background, data = alpha_shan)
summary(testback) #p value =0.3478 and Adj R2 =-0.003471
hist(resid(testback))
qqnorm(resid(testback))
qqline(resid(testback))
# non normal visually
# shapiro-wilkes to confirm
shapiro.test(alpha_shan$Shannon)
# homogeneity of variance
leveneTest(Shannon ~ Background, data = alpha_shan) # not significant (0.6619), equal!
leveneTest(Shannon ~ Intervention, data = alpha_shan) # not significant (0.3723), equal!
# transformation of data
alpha_shan$log_Shannon <- log(alpha_shan$Shannon)
# SW test
shapiro.test(alpha_shan$log_Shannon) #nope still not normal p-value = 1.731e-05
# Levene's
leveneTest(log_Shannon ~ Background, data = alpha_shan) #not significant (0.4776), equal!
leveneTest(log_Shannon ~ Intervention, data = alpha_shan) #not significant (0.3146), equal!
# box-cox transformation
bc <- boxcox(lm(Shannon ~ 1, data = alpha_shan))
lambda <- bc$x[which.max(bc$y)]
alpha_shan$bc_Shannon <- (alpha_shan$Shannon^lambda - 1) / lambda
# SW test
shapiro.test(alpha_shan$bc_Shannon) #nope still not normal p-value = 0.01012
# Levene's
leveneTest(bc_Shannon ~ Background, data = alpha_shan) #not significant (0.9021), equal!
leveneTest(bc_Shannon ~ Intervention, data = alpha_shan) #not significant (0.4362), equal!
# Shannon Kruskal Wallis
# using KW on all independent variables
kruskalShannonBack <- kruskal.test(Shannon ~ Background, data = alpha_shan)
kruskalShannonBack
# Shannon Kruskal Wallis
# using KW on all independent variables
kruskalShannonBack <- kruskal.test(Shannon ~ Background + Intervention, data = alpha_shan)
View(ps_rel)
View(sampdf)
# Kruskal Wallis
# using KW on all independent variables
kruskalShannon <- kruskal.test(Shannon ~ Sample_Type, data = alpha_shan)
kruskalShannon
# Calculate pairwise comparisons Dunn's Test if significant KW
#using bonferroni's correct as there are less comparisons
Dunn <- dunnTest(Shannon ~ Sample_Type, data=alpha_shan, method="bonferroni")
Dunn #
# Mann U test Background
wilcox_back <- wilcox.test(Shannon ~ Background,
paired = FALSE, # Set to TRUE only if measurements are paired
alternative = "two.sided")
# Mann U test Background
wilcox_back <- wilcox.test(Shannon ~ Background,  alternative = "two.sided")
# Mann U test Background
wilcox_back <- wilcox.test(Shannon ~ Background,  alternative = "two.sided", data = alpha_shan)
wilcox_back
# Mann U test Intervention
wilcox_int <- wilcox.test(Shannon ~ Intervention,  alternative = "two.sided", data = alpha_shan)
wilcox_int #p-value = 0.4095
plot_richness(ps_rel, measures=c("Chao1", "Shannon", "Simpson"))
# load ps from relative abundance without controls
ps_rel <- readRDS("R/ps_decontam.rds")
ntaxa(ps_rel) #788
# make df with SampleID as rownames
sampdf <- sample_data(ps_rel) %>%
data.frame() %>%
rownames_to_column(var = "SampleID")
View(ps_rel)
# get diversity
alpha_shan <- estimate_richness(ps_rel, measures = "Shannon") %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
alpha_simp <- estimate_richness(ps_rel, measures = "Simpson") %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
View(alpha_simp)
# get diversity
alpha <- estimate_richness(ps_rel, measures = "Observed", "Chao1", "Shannon", "Simpson") %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
# get diversity
alpha <- estimate_richness(ps_rel, measures = c("Observed", "Chao1", "Shannon", "Simpson")) %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
View(alpha)
# get diversity
alpha <- estimate_richness(ps_rel, measures = c("Observed", "Chao1")) %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
# get diversity
alpha <- estimate_richness(ps_rel) %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
# load ps from relative abundance without controls
ps_rel <- readRDS("R/ps_decontam.rds")
ntaxa(ps_rel) #788
# make df with SampleID as rownames
sampdf <- sample_data(ps_rel) %>%
data.frame() %>%
rownames_to_column(var = "SampleID")
# get diversity
alpha <- estimate_richness(ps_rel) %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
View(alpha)
# get diversity
alpha <- estimate_richness(ps_rel, measures = "Shannon") %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
# get diversity
alpha <- estimate_richness(ps_rel, measures = "Shannon", "Simpson") %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
# get diversity
alpha <- estimate_richness(ps_rel, measures = c("Shannon", "Simpson")) %>%
# make ID
rownames_to_column(var = "SampleID") %>%
merge(sampdf, by = "SampleID")
View(alpha)
# get summary statistics
sum <- alpha %>%
group_by(Intervention, Background) %>% get_summary_stats(Shannon, type = "mean_sd")
# get summary statistics for Shannon
sum <- alpha %>%
group_by(Intervention, Background) %>% get_summary_stats(Shannon, type = "mean_sd")
write.table(sum, file = "out/shannon-sum-stats.txt", sep = "\t", row.names = FALSE)
# exploratory smoothed histogram
ggdensity(alpha, x = "Shannon", fill = "Intervention")
ggdensity(alpha, x = "Shannon", fill = "Background")
# exploratory plots
hist(alpha$Shannon) #defintely skewed
ggboxplot(alpha, x = "Intervention", y = "Shannon", facet.by = "Background")
# check on outliers for shannon
# table for determining outlier range
st <- alpha %>% get_summary_stats(Shannon, type = "mean_sd") %>%
mutate(sdx3 = sd * 3,
outhi = mean + sdx3,
outlo = mean - sdx3)
# SD of Shannon is 0.714; Range is 1.555 to 5.839
outliershannon <- alpha$SampleID[alpha$Shannon < st$outlo] # none
alpha$SampleID[alpha$Shannon > st$outhi] # no upper outliers
# build test model for linear assumption of Intervention
# Convert Intervention to factor
alpha$Intervention <- factor(alpha$Intervention)
# Convert Background to factor
alpha$Background <- factor(alpha$Background)
# set reference level
alpha$Intervention <- relevel(alpha$Intervention, ref = "control")
# run linear model
testint <- lm(Shannon ~ Intervention, data = alpha)
#%>%
# filter(isoutlier == F)) # more normal if outliers removed
summary(testint) #p value = 0.548 Adj R2 = -0.02807
hist(resid(testint))
qqnorm(resid(testint))
qqline(resid(testint))
# build test model for linear assumption of Background
# set reference level
alpha$Background <- relevel(alpha$Background, ref = "normal total bile acid level")
testback <- lm(Shannon ~ Background, data = alpha)
summary(testback) #p value =0.345 and Adj R2 =-0.002947
hist(resid(testback))
qqnorm(resid(testback))
qqline(resid(testback))
# non normal visually
# shapiro-wilkes to confirm
shapiro.test(alpha$Shannon)
# homogeneity of variance
leveneTest(Shannon ~ Background, data = alpha) # not significant (0.6592), equal!
leveneTest(Shannon ~ Intervention, data = alpha) # not significant (0.3703), equal!
# transformation of data
alpha$log_Shannon <- log(alpha$Shannon)
# SW test
shapiro.test(alpha$log_Shannon) #nope still not normal p-value = 1.689e-05
# Levene's
leveneTest(log_Shannon ~ Background, data = alpha) #not significant (0.476), equal!
leveneTest(log_Shannon ~ Intervention, data = alpha) #not significant (0.3133), equal!
# box-cox transformation
bc <- boxcox(lm(Shannon ~ 1, data = alpha))
lambda <- bc$x[which.max(bc$y)]
alpha$bc_Shannon <- (alpha$Shannon^lambda - 1) / lambda
# SW test
shapiro.test(alpha$bc_Shannon) #nope still not normal p-value = 0.009834
# Levene's
leveneTest(bc_Shannon ~ Background, data = alpha) #not significant (0.8985), equal!
leveneTest(bc_Shannon ~ Intervention, data = alpha) #not significant (0.4334), equal!
# Mann U test Intervention
wilcox_int <- wilcox.test(Shannon ~ Intervention,  alternative = "two.sided", data = alpha)
wilcox_int #p-value = 0.9774 non-significant
wilcox_int <- wilcox.test(Simpson ~ Intervention,  alternative = "two.sided", data = alpha)
wilcox_int #p-value = 0.9774 non-significant
# Mann U test Intervention
wilcox_int <- wilcox.test(Shannon ~ Intervention,  alternative = "two.sided", data = alpha)
wilcox_int #p-value = 0.9774 non-significant
kruskalSimpson <- kruskal.test(Simpson ~ Sample_Type, data = alpha)
kruskalSimpson
#plots
ggplot(alpha, aes(x=Background, y = Shannon, fill = Intervention))+
geom_violin(trim = FALSE, alpha = 0.8)+
geom_jitter(size = 1, width = 0.5, height = 0.2)+
scale_fill_manual(values = c("#936639", "#656d4a"))+
theme_bw()
#plots
ggplot(alpha, aes(x=Background, y = Shannon, fill = Intervention))+
geom_violin(trim = FALSE, alpha = 0.8)+
geom_jitter(size = 1)+
scale_fill_manual(values = c("#936639", "#656d4a"))+
theme_bw()
ggplot(alpha, aes(x=Background, y = Simpson, fill = Intervention))+
geom_violin(trim = FALSE, alpha = 0.8)+
geom_jitter(size = 1)+
scale_fill_manual(values = c("#936639", "#656d4a"))+
theme_bw()
#plots
ggplot(alpha, aes(x=Background, y = Shannon, fill = Intervention))+
geom_violin(trim = FALSE, alpha = 0.8)+
#geom_jitter(size = 1)+
scale_fill_manual(values = c("#936639", "#656d4a"))+
theme_bw()
ggplot(alpha, aes(x=Background, y = Simpson, fill = Intervention))+
geom_violin(trim = FALSE, alpha = 0.8)+
#geom_jitter(size = 1)+
scale_fill_manual(values = c("#936639", "#656d4a"))+
theme_bw()
plot_richness(ps_rel, measures=c("Chao1", "Shannon", "Simpson"))
plot_richness(ps_rel, x="Sample_Type" measures=c("Chao1", "Shannon", "Simpson"))
View(ps_rel)
plot_richness(ps_rel, x = "Sample_Type", measures = c("Chao1", "Shannon", "Simpson"))
#plots
ggplot(alpha, aes(x=Background, y = Shannon, fill = Intervention))+
geom_violin(trim = FALSE, alpha = 0.8)+
#geom_jitter(size = 1)+
scale_fill_manual(values = c("#936639", "#656d4a"))+
theme_bw()
ggsave("viz/alpha.pdf", plot = last_plot(), height = 20, width = 26, units = "in")
ggsave("viz/alpha_shannon.pdf", plot = last_plot(), height = 20, width = 26, units = "in")
plot_richness(ps_rel, x = "Sample_Type", measures = c("Chao1", "Shannon", "Simpson"))
ggsave("viz/alpha.pdf", plot = last_plot(), height = 20, width = 26, units = "in")
# ---- beta diversity  ----
library(vegan)
library(pairwiseAdonis)
library(microViz)
#for reproducibility
set.seed(123245)
#load ps-filt
load("R/RData/ps_decontam.Rds") # is it .Rds not RData?
#load ps-filt
ps_decon <- readRDS("R/RData/ps_decontam.Rds")
#load ps-filt
ps_decon <- readRDS("R/ps_decontam.Rds")
# check wd
getwd()
# set wd if needed
setwd("/Users/sls6550/work/hTBA_Alc_Singh")
# check wd to confirm change
getwd()
# SET PATHS
RDATA = "R"
#exploratory
ps_decon %>%
tax_fix() %>%
tax_transform("compositional", rank = "Genus") %>%
dist_calc("aitchison") %>%
dist_permanova(
variables = c("Intervention", "Background"),
perm = 9999
) #Intervention p = 0.001, Background p = 0.018
ntaxa(ps_decon)
#exploratory
ps_decon %>%
tax_fix() %>%
tax_transform("compositional", rank = "Genus") %>%
dist_calc("aitchison") %>%
dist_permanova(
variables = c("Intervention", "Background"),
perm = 9999
) #Intervention p = 0.001, Background p = 0.017
# clr transform phyloseq objects at Genus level
beta <- ps_decon %>%
# clr transform to normalize
tax_fix() %>%
tax_transform(trans = "clr", rank = "Genus")
ps_get(beta) #81 taxa
# generate distance matrix
psdist <- phyloseq::distance(beta, method = "euclidean")
#ADONIS test
# Intervention
adonis2(psdist ~ sample_data(beta)$Intervention, permutations = 10000)
# Background
adonis2(psdist ~ sample_data(beta)$Background, permutations = 10000)
# Background
adonis2(psdist ~ sample_data(beta)$Background, permutations = 10000)
#ADONIS test
# Intervention
adonis2(psdist ~ sample_data(beta)$Intervention, permutations = 10000)
# Background
adonis2(psdist ~ sample_data(beta)$Background, permutations = 10000)
#pairwise for Sample_type
#what is this function: pairwise.adonis()?????
statdf <- pairwise.adonis(psdist, phyloseq::sample_data(beta)$Sample_Type)
statdf
#save table
write.table(statdf, file = file.path("out/pairwise-adonis.txt"), sep = "\t")
#beta diversity
beta %>%
# when no distance matrix or constraints are supplied, PCA is the default/auto ordination method
ord_calc() %>%
ord_plot(color = "Sample_Type", shape = "Intervention", size = 10, alpha=0.5) +
scale_color_viridis_d(option = 4, begin = 0.4, end = 0.8, direction= 1) +
stat_ellipse(aes(colour = Sample_Type))+
theme(axis.title= element_text(size = 20, color = "black"),
axis.text = element_text(size = 20, color = "black"),
legend.position = "right")
earth_pal <- c("#7F4F24", "#936639", "#656D4A", "#414833")
earth_pal <- c("#7F4F24", "#936639", "#656D4A", "#414833")
#beta diversity
beta %>%
# when no distance matrix or constraints are supplied, PCA is the default/auto ordination method
ord_calc() %>%
ord_plot(color = "Sample_Type", shape = "Intervention", size = 10, alpha=0.5) +
scale_color_manual(values = earth_pal) +
stat_ellipse(aes(colour = Sample_Type))+
theme(axis.title= element_text(size = 20, color = "black"),
axis.text = element_text(size = 20, color = "black"),
legend.position = "right")
earth_pal <- c("#582F0E", "#A68A64", "#A4AC86", "#333D29")
#beta diversity
beta %>%
# when no distance matrix or constraints are supplied, PCA is the default/auto ordination method
ord_calc() %>%
ord_plot(color = "Sample_Type", shape = "Intervention", size = 10, alpha=0.5) +
scale_color_manual(values = earth_pal) +
stat_ellipse(aes(colour = Sample_Type))+
theme(axis.title= element_text(size = 20, color = "black"),
axis.text = element_text(size = 20, color = "black"),
legend.position = "right")
#save file of plot
ggsave("R/betadiv_bytype_genus.pdf", plot = last_plot())
#save file of plot
ggsave("viz/betadiv_bytype_genus.pdf", plot = last_plot())
# load ps from decontam
ps_decon <- ("R/ps_decontam.Rds")
library(ALDEx2)
library(tidyverse)
library(microViz)
library(phyloseq)
# check wd
getwd()
# set wd if needed
setwd("/Users/sls6550/work/hTBA_Alc_Singh")
# check wd to confirm change
getwd()
# load ps from decontam
ps_decon <- ("R/ps_decontam.Rds")
# Trying multiple variable statistics in Aldex2
otu_table_decontam <- as.data.frame(phyloseq::otu_table(psfdecon))
library(ALDEx2)
library(tidyverse)
library(microViz)
library(phyloseq)
# check wd
getwd()
# set wd if needed
setwd("/Users/sls6550/work/hTBA_Alc_Singh")
# check wd to confirm change
getwd()
# load ps from decontam
ps_decon <- ("R/ps_decontam.Rds")
# Trying multiple variable statistics in Aldex2
otu_table_decontam <- as.data.frame(phyloseq::otu_table(ps_decon))
# load ps from decontam
ps_decon <- readRDS("R/ps_decontam.Rds")
library(ALDEx2)
library(tidyverse)
library(microViz)
library(phyloseq)
# check wd
getwd()
# set wd if needed
setwd("/Users/sls6550/work/hTBA_Alc_Singh")
# check wd to confirm change
getwd()
# load ps from decontam
ps_decon <- readRDS("R/ps_decontam.Rds")
# Trying multiple variable statistics in Aldex2
otu_table_decontam <- as.data.frame(phyloseq::otu_table(ps_decon))
meta_decontam <- data.frame(phyloseq::sample_data(ps_decon))
# confirm class type
class(otu_table_decontam)
class(meta_decontam)
# check assumptions of ttest
# normality is assumed to be false due to count-based data, zero-inflation, skew, and non-independence
# equal variance
# Convert OTU table into long format: one row per OTU sample pair
otu_lev <- otu_table_decontam %>%
as.data.frame() %>%
mutate(Sample_Type = meta_decontam$Sample_Type) %>%
gather(key = "OTU", value = "Count", -Sample_Type)
# Run Levene's Test (Check variance across different groups)
library(car)
leveneTest(Count ~ Sample_Type, data = otu_lev) # equal variance
# need to make sure formating of tables is good for aldex.clr
all(colnames(otu_table_decontam) == rownames(meta_decontam))
# Should return FALSE, check visually
dim(otu_table_decontam)  # Returns features, samples (24, 785)
dim(meta_decontam) # Returns samples, features (24, 7)
# NEED samples to be the same
# Transpose the rows to columns
otu_table_decontam <- t(otu_table_decontam)
all(colnames(otu_table_decontam) == rownames(meta_decontam))
# Should return TRUE, check visually
# test clr on Intervention to check
clr_int <- aldex.clr(otu_table_decontam, conds = meta_decontam$Intervention)
#---- Run sensitivity analysis function (Derived from SK) ----
##Plotting TP and FP over different levels of gamma
gamma.to.test <- c(0, 0.1, 0.3, 0.5, 1, 3, 5)
sen_res_int <- aldex.senAnalysis(clr_int, gamma = gamma.to.test)
